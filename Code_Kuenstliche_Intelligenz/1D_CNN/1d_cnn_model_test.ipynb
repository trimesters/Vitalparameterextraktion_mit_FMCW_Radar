{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c2fcff-1d84-46b1-abba-387216d87457",
   "metadata": {},
   "source": [
    "# Algorithmus für künstliche Intelligenz mit CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60dc300-a77c-4fbc-9740-a019f619e386",
   "metadata": {},
   "source": [
    "## Libaray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d3a56a-304d-4e05-a93e-862cd647b9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import optuna\n",
    "\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d2136-47c8-4570-82ae-6281da1afbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6e9b2-9d7d-4bdc-a7fb-17f7e73ba928",
   "metadata": {},
   "source": [
    "## Modell auf der GPU ausführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad082b2-e2d6-4794-99ca-754588e54b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4a867a-9cb3-468e-8368-82281bcb3b64",
   "metadata": {},
   "source": [
    "## Modell Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cd0c4b-47a0-4b99-8b5f-e423919bdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"1d_cnn_model_test\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae871c7-68b7-43ba-aa9a-44dc5c92d040",
   "metadata": {},
   "source": [
    "## Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c974fe44-ee94-49ec-a91b-56e57ca1a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Load_Data:\n",
    "    \n",
    "    def __init__(self, root_dir = \"\"):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        self.signal_list_all = []\n",
    "        self.lable_list_all = []\n",
    "        \n",
    "        self.signal_list_80 = []\n",
    "        self.signal_list_20 = []\n",
    "        self.lable_list_80 = []\n",
    "        self.lable_list_20 = []\n",
    "        \n",
    "        self.load_data()\n",
    "        self.sort_data()\n",
    "        \n",
    "    def load_data(self):\n",
    "        \n",
    "        for dirpath, dirnames, filenames in os.walk(self.root_dir):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith(\".npz\"): \n",
    "                    \n",
    "                    file_path = os.path.join(dirpath, filename)\n",
    "                    data = np.load(file_path)\n",
    "\n",
    "                    signal_ = data[\"signal\"]\n",
    "                    signal_full = signal_[np.newaxis] # An additional dimension is needed for later processing\n",
    "                    signal = signal_full[:,::]  # Halving of the input data and thus of the features\n",
    "                    \n",
    "                    heart_rate = data[\"heart_uart\"]\n",
    "                    respiration_rate = data[\"respiration_radar\"]\n",
    "                    \n",
    "                    heart_rate_t = heart_rate\n",
    "                    respiration_rate_t = respiration_rate\n",
    "                    signal_t = signal\n",
    "   \n",
    "                    self.lable_list_all.append([heart_rate_t, respiration_rate_t])\n",
    "                    self.signal_list_all.append(signal_t)\n",
    "    \n",
    "    def sort_data(self):   \n",
    "        \n",
    "        lable = np.array(self.lable_list_all)\n",
    "        signal = np.array(self.signal_list_all)\n",
    "\n",
    "        unique_elements, counts_elements = np.unique(lable[:,0], return_counts=True)\n",
    "        \n",
    "        print(counts_elements)\n",
    "        print(unique_elements)\n",
    "        \n",
    "        for element in unique_elements:\n",
    "            \n",
    "            total_count = counts_elements[np.where(unique_elements == element)]\n",
    "            \n",
    "            count_80 = int(total_count * 0.8)\n",
    "            \n",
    "            arr_l_80, arr_l_20 = np.split(lable[(lable[:,0] == element)], [count_80])\n",
    "            arr_s_80, arr_s_20 = np.split(signal[(lable[:,0] == element)], [count_80])\n",
    "\n",
    "            for count in range(len(arr_l_80)):\n",
    "                self.lable_list_80.append(arr_l_80[count])\n",
    "                \n",
    "            for count in range(len(arr_l_20)):   \n",
    "                self.lable_list_20.append(arr_l_20[count])\n",
    "                \n",
    "            for count in range(len(arr_l_80)):\n",
    "                self.signal_list_80.append(arr_s_80[count])\n",
    "                \n",
    "            for count in range(len(arr_l_20)):   \n",
    "                self.signal_list_20.append(arr_s_20[count])     \n",
    "                \n",
    "    def get_dataset_80(self):   \n",
    "        return self.signal_list_80, self.lable_list_80\n",
    "        \n",
    "    def get_dataset_20(self):   \n",
    "        return self.signal_list_20, self.lable_list_20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "347a6384-6aa6-4216-8bb9-6701497bf15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, signal_list, lable_list):\n",
    "\n",
    "        self.lable_list_ = lable_list\n",
    "        self.signal_list_ = signal_list\n",
    "        self.lable_list = []\n",
    "        self.signal_list = []\n",
    "        \n",
    "        self.append_data()\n",
    "\n",
    "    def append_data(self):\n",
    "        \n",
    "        lable = np.array(self.lable_list_)\n",
    "        signal = np.array(self.signal_list_)\n",
    "\n",
    "        lable_ = torch.from_numpy(lable).float().to(device)\n",
    "        signal_ = torch.from_numpy(signal).float().to(device)\n",
    "        \n",
    "        for value in lable_:\n",
    "            self.lable_list.append(value)\n",
    "            \n",
    "        for value in signal_:\n",
    "            self.signal_list.append(value)\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "\n",
    "        return len(self.lable_list) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.signal_list[idx], self.lable_list[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e1f8b4-93cc-4a57-839a-f70320badf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6  20  50  49  65 113 160 230 224 251 206 220 106 223 221 157 120 207\n",
      " 167 118 131  71  76 113  19  10   9   9   7   2]\n",
      "[63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86\n",
      " 87 88 89 90 91 92]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_folder_train = \"data\"\n",
    "dataset = Load_Data(root_folder_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacf7210-7317-45f5-8fba-761d10185ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signal_list_80, lable_list_80 = dataset.get_dataset_80()\n",
    "dataset_train = MyDataset(signal_list_80, lable_list_80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3a87b8-b2bf-41df-8e18-20304e6607b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signal_list_20, lable_list_20 = dataset.get_dataset_20()\n",
    "dataset_test = MyDataset(signal_list_20, lable_list_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c27089-8e16-4892-baab-a3b300b9c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f2f91c1-803b-43f0-8fa0-86552b9acc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 1, 1500])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 1])\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i_batch, (inputs, targets) in enumerate(dataloader_train):\n",
    "\n",
    "    print(i_batch)\n",
    "    print(inputs.shape)\n",
    "    print(targets.shape)\n",
    "    print(targets[:,0:1].shape)\n",
    "    print(\"next\")\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cea146b-d796-4378-a7c5-2f6783beb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d8db1f-ff06-4e62-a586-c8d0f7de18bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 1, 1500])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 1])\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i_batch, (inputs, targets) in enumerate(dataloader_test):\n",
    "\n",
    "    print(i_batch)\n",
    "    print(inputs.shape)\n",
    "    print(targets.shape)\n",
    "    print(targets[:,0:1].shape)\n",
    "    print(\"next\")\n",
    "\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59323b-77c4-4e5c-803f-4395b53a0d0c",
   "metadata": {},
   "source": [
    "## Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "758b3871-0eff-4d39-9127-1d5d81020161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Pulse_Respiration_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_width, \n",
    "                 conv_layer_, \n",
    "                 fc_layers_, \n",
    "                 conv_channel_, \n",
    "                 conv_kernel_, \n",
    "                 conv_stride_,\n",
    "                 pool_kernel_, \n",
    "                 pool_stride_,\n",
    "                 fully_connected_):\n",
    "        \n",
    "        super(Pulse_Respiration_CNN, self).__init__()\n",
    "\n",
    "        self.af_1 = nn.Tanh()\n",
    "        self.af_2 = nn.ReLU()\n",
    "\n",
    "        self.conv_1_layers = nn.ModuleList()\n",
    "        self.bn_1_layers = nn.ModuleList()\n",
    "        self.pool_1_layers = nn.ModuleList()\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        \n",
    "        conv_layer = conv_layer_\n",
    "        fc_layers = fc_layers_\n",
    "        \n",
    "        print(f\"conv_layer: {conv_layer}\")\n",
    "        print(f\"fc_layers: {fc_layers}\")\n",
    "\n",
    "        Width = input_width\n",
    "        in_channels = 1\n",
    "\n",
    "        for i in range(conv_layer):\n",
    "            \n",
    "            conv_channel = conv_channel_[i]\n",
    "            conv_kernel = conv_kernel_[i]\n",
    "            conv_stride = conv_stride_[i]\n",
    "            \n",
    "            pool_kernel = pool_kernel_[i]\n",
    "            pool_stride = pool_stride_[i]\n",
    "     \n",
    "            Kernel = conv_kernel # kernel_size\n",
    "            Padding = 0 # (Kernel - 1) // 2 # padding\n",
    "            Stride = conv_stride # stride\n",
    "            Width_a = ((Width - conv_kernel + 2 * Padding) // conv_stride) + 1\n",
    "            \n",
    "            Width_b = ((Width_a - pool_kernel) // pool_stride) + 1\n",
    "            \n",
    "            if (Width_b < 4):\n",
    "                Kernel = conv_kernel * conv_stride + pool_kernel * pool_stride\n",
    "            \n",
    "                Padding = (Kernel - 1) // 2 # padding\n",
    "                Width = ((Width - conv_kernel + 2 * Padding) // conv_stride) + 1\n",
    "                Width = ((Width - pool_kernel) // pool_stride) + 1\n",
    "            else:\n",
    "                Width = Width_b\n",
    "            \n",
    "            self.conv_1_layers.append(nn.Conv1d(in_channels=in_channels, \\\n",
    "                out_channels=conv_channel, kernel_size=conv_kernel, \\\n",
    "                stride=conv_stride, padding=Padding))\n",
    "            self.bn_1_layers.append(nn.BatchNorm1d(conv_channel))\n",
    "            self.pool_1_layers.append(nn.MaxPool1d(pool_kernel, pool_stride)) \n",
    "            in_channels = conv_channel\n",
    "            \n",
    "            print(f\"s{i}_conv_channel_1: {conv_channel}, \" + \\\n",
    "                f\"s{i}_conv_kernel_1: {conv_kernel}, \" + \\\n",
    "                f\"s{i}_conv_stride_1: {conv_stride}, \" + \\\n",
    "                f\"s{i}_padding_1: {Padding}, \" + \\\n",
    "                f\"s{i}_pool_kernel_1: {pool_kernel}, \" + \\\n",
    "                f\"s{i}_pool_stride_1: {pool_stride}, \" + \\\n",
    "                f\"s{i}_Width_1: {Width}\")\n",
    "\n",
    "        out_features = Width * in_channels\n",
    "        \n",
    "        print(f\"s{i}_features: {out_features}, \" + \\\n",
    "            f\"Width: {Width} * in_channels: {in_channels}\")\n",
    "\n",
    "        for i in range(fc_layers):\n",
    "            \n",
    "            out_features_next = fully_connected_[i]\n",
    "            self.fc_layers.append(nn.Linear(in_features=out_features, \\\n",
    "                out_features=out_features_next))\n",
    "            out_features = out_features_next\n",
    "            \n",
    "            print(f\"s{i}_fully_connected_: {out_features_next}\")\n",
    "            \n",
    "        self.fc_out = nn.Linear(in_features=out_features, out_features=1)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for conv_1, bn_1, pool_1 in zip(self.conv_1_layers, self.bn_1_layers, \\\n",
    "            self.pool_1_layers):\n",
    "            \n",
    "            x = conv_1(x)\n",
    "            x = bn_1(x)\n",
    "            x = self.af_1(x)\n",
    "            x = pool_1(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        for layer_1 in self.fc_layers:\n",
    "            \n",
    "            x = layer_1(x)\n",
    "            x = self.af_2(x)\n",
    "            \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101f963-b750-4d50-b67b-c056b92f77d1",
   "metadata": {},
   "source": [
    "## Modellinstanz erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5657fd8-bc74-4319-95ea-e3173bb1deae",
   "metadata": {},
   "source": [
    "### Parameter \n",
    "\n",
    "##### conv_layer: 8\n",
    "##### fc_layers: 2\n",
    "##### s0_conv_channel_1: 16 s0_conv_kernel_1: 7 s0_conv_stride_1: 1 s0_padding_1: 0 s0_pool_kernel_1: 5 s0_pool_stride_1: 2 s0_Width_1: 745\n",
    "##### s1_conv_channel_1: 16 s1_conv_kernel_1: 29 s1_conv_stride_1: 1 s1_padding_1: 0 s1_pool_kernel_1: 5 s1_pool_stride_1: 1 s1_Width_1: 713\n",
    "##### s2_conv_channel_1: 16 s2_conv_kernel_1: 3 s2_conv_stride_1: 1 s2_padding_1: 0 s2_pool_kernel_1: 3 s2_pool_stride_1: 1 s2_Width_1: 709\n",
    "##### s3_conv_channel_1: 32 s3_conv_kernel_1: 29 s3_conv_stride_1: 1 s3_padding_1: 0 s3_pool_kernel_1: 4 s3_pool_stride_1: 1 s3_Width_1: 678\n",
    "##### s4_conv_channel_1: 16 s4_conv_kernel_1: 3 s4_conv_stride_1: 1 s4_padding_1: 0 s4_pool_kernel_1: 4 s4_pool_stride_1: 1 s4_Width_1: 673\n",
    "##### s5_conv_channel_1: 64 s5_conv_kernel_1: 29 s5_conv_stride_1: 1 s5_padding_1: 0 s5_pool_kernel_1: 3 s5_pool_stride_1: 1 s5_Width_1: 643\n",
    "##### s6_conv_channel_1: 32 s6_conv_kernel_1: 7 s6_conv_stride_1: 1 s6_padding_1: 0 s6_pool_kernel_1: 4 s6_pool_stride_1: 1 s6_Width_1: 634\n",
    "##### s7_conv_channel_1: 16 s7_conv_kernel_1: 17 s7_conv_stride_1: 1 s7_padding_1: 0 s7_pool_kernel_1: 5 s7_pool_stride_1: 1 s7_Width_1: 614\n",
    "##### s7_features: 9824 = Width: 614 * in_channels: 16\n",
    "##### s0_fully_connected_: 32\n",
    "##### s1_fully_connected_: 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac2c3be-02c3-4a1c-b609-5b82adbc0281",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_model():\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for i_batch, (inputs, targets) in enumerate(dataloader_train):\n",
    "        input_s_ = inputs.shape[2]\n",
    "        \n",
    "    conv_layer = 8\n",
    "    fc_layers = 2\n",
    "    \n",
    "    conv_channel = [16,16,16,32,16,64,32,16]\n",
    "    conv_kernel = [5,29,3,29,3,29,7,17]\n",
    "    conv_stride = [2,1,1,1,1,1,1,1]\n",
    "    pool_kernel = [5,5,3,4,4,3,4,5]\n",
    "    pool_stride = [2,1,1,1,1,1,1,1]\n",
    "    \n",
    "    fully_connected = [32,32]\n",
    "\n",
    "    model = Pulse_Respiration_CNN(input_width = input_s_, \n",
    "                                  conv_layer_ = conv_layer, \n",
    "                                  fc_layers_ = fc_layers, \n",
    "                                  conv_channel_ = conv_channel, \n",
    "                                  conv_kernel_ = conv_kernel, \n",
    "                                  conv_stride_ = conv_stride,\n",
    "                                  pool_kernel_ = pool_kernel, \n",
    "                                  pool_stride_ = pool_stride,\n",
    "                                  fully_connected_ = fully_connected).to(device)\n",
    "\n",
    "    dateipfad = model_name\n",
    "    \n",
    "    if os.path.isfile(dateipfad):\n",
    "        print(\"Die Datei existiert.\")\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "        \n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    L2_regularization = 1e-5 # recommended = 1e-5 # default = 0\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=L2_regularization) \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    epochs = 1000\n",
    "    valid_loss_last = 100.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i_batch, (inputs, targets) in enumerate(dataloader_train):\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, targets[:,0:1]) # breathing and heart\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss = train_loss /len(dataloader_train)\n",
    "            \n",
    "        model.eval() \n",
    "        valid_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for i_batch, (inputs, targets) in enumerate(dataloader_test):\n",
    "\n",
    "                outputs = model(inputs) \n",
    "                loss = criterion(outputs, targets[:,0:1]) \n",
    "                valid_loss += loss.item()\n",
    "\n",
    "            valid_loss = valid_loss /len(dataloader_test)\n",
    "\n",
    "        if (epoch + 3) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch + 3}/{epochs}], Run Loss: {train_loss:.4f}, Val Loss: {valid_loss:.4f}\")\n",
    "        \n",
    "        if (epoch + 2) % 1000 == 0:\n",
    "            print(f\"predictions [{outputs.cpu().numpy()[0]}], targets: {targets[:,0:1].cpu().numpy()[0]}\")\n",
    "        \n",
    "        if (valid_loss < valid_loss_last):\n",
    "            valid_loss_last = valid_loss\n",
    "            torch.save(model.state_dict(), model_name + \".pt\")\n",
    "            print(f\"Train Loss: {train_loss}, Valid Loss: {valid_loss}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Die Ausführungszeit beträgt: {execution_time} s\")\n",
    "    \n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d614b8f-a57b-4bd5-8b82-2bb533abad5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layer: 8\n",
      "fc_layers: 2\n",
      "s0_conv_channel_1: 16, s0_conv_kernel_1: 5, s0_conv_stride_1: 2, s0_padding_1: 0, s0_pool_kernel_1: 5, s0_pool_stride_1: 2, s0_Width_1: 372\n",
      "s1_conv_channel_1: 16, s1_conv_kernel_1: 29, s1_conv_stride_1: 1, s1_padding_1: 0, s1_pool_kernel_1: 5, s1_pool_stride_1: 1, s1_Width_1: 340\n",
      "s2_conv_channel_1: 16, s2_conv_kernel_1: 3, s2_conv_stride_1: 1, s2_padding_1: 0, s2_pool_kernel_1: 3, s2_pool_stride_1: 1, s2_Width_1: 336\n",
      "s3_conv_channel_1: 32, s3_conv_kernel_1: 29, s3_conv_stride_1: 1, s3_padding_1: 0, s3_pool_kernel_1: 4, s3_pool_stride_1: 1, s3_Width_1: 305\n",
      "s4_conv_channel_1: 16, s4_conv_kernel_1: 3, s4_conv_stride_1: 1, s4_padding_1: 0, s4_pool_kernel_1: 4, s4_pool_stride_1: 1, s4_Width_1: 300\n",
      "s5_conv_channel_1: 64, s5_conv_kernel_1: 29, s5_conv_stride_1: 1, s5_padding_1: 0, s5_pool_kernel_1: 3, s5_pool_stride_1: 1, s5_Width_1: 270\n",
      "s6_conv_channel_1: 32, s6_conv_kernel_1: 7, s6_conv_stride_1: 1, s6_padding_1: 0, s6_pool_kernel_1: 4, s6_pool_stride_1: 1, s6_Width_1: 261\n",
      "s7_conv_channel_1: 16, s7_conv_kernel_1: 17, s7_conv_stride_1: 1, s7_padding_1: 0, s7_pool_kernel_1: 5, s7_pool_stride_1: 1, s7_Width_1: 241\n",
      "s7_features: 3856, Width: 241 * in_channels: 16\n",
      "s0_fully_connected_: 32\n",
      "s1_fully_connected_: 32\n",
      "Train Loss: 1217.5506593670164, Valid Loss: 30.908258351412687\n",
      "Train Loss: 10.459054566565014, Valid Loss: 13.657935619354248\n",
      "Train Loss: 7.158544126011076, Valid Loss: 10.937265580350703\n",
      "Train Loss: 6.121865874245053, Valid Loss: 10.745839140631936\n",
      "Train Loss: 5.919315319685709, Valid Loss: 8.127867276018316\n",
      "Train Loss: 4.919683226517269, Valid Loss: 8.00459698113528\n",
      "Train Loss: 5.127139751400266, Valid Loss: 7.536564241756093\n",
      "Train Loss: 4.383941634779885, Valid Loss: 7.525092027404091\n",
      "Train Loss: 4.5981553083374385, Valid Loss: 7.399141398343173\n",
      "Train Loss: 3.9170045128890445, Valid Loss: 7.08506598255851\n",
      "Train Loss: 2.9440612083389643, Valid Loss: 6.216016119176691\n",
      "Train Loss: 2.6261432582423803, Valid Loss: 6.194281534715132\n",
      "Train Loss: 2.5036252602225257, Valid Loss: 5.753302454948425\n",
      "Train Loss: 2.814111891246977, Valid Loss: 5.0357925133271655\n",
      "Train Loss: 2.5039167546090626, Valid Loss: 4.811486059969122\n",
      "Train Loss: 1.8868126613753182, Valid Loss: 4.579017693346197\n",
      "Train Loss: 2.0347586572170258, Valid Loss: 4.470134464177218\n",
      "Train Loss: 1.7232651731797628, Valid Loss: 4.134518693793904\n",
      "Epoch [100/1000], Run Loss: 1.0212, Val Loss: 6.8280\n",
      "Train Loss: 0.924967422371819, Valid Loss: 3.938387231393294\n",
      "Train Loss: 0.8245572394558361, Valid Loss: 3.7820026982914317\n",
      "Epoch [200/1000], Run Loss: 0.3608, Val Loss: 6.2513\n",
      "Epoch [300/1000], Run Loss: 0.2473, Val Loss: 5.5340\n",
      "Train Loss: 0.23498576950459255, Valid Loss: 3.7407417622479526\n",
      "Epoch [400/1000], Run Loss: 0.1323, Val Loss: 5.0900\n",
      "Epoch [500/1000], Run Loss: 0.2468, Val Loss: 4.6566\n",
      "Epoch [600/1000], Run Loss: 0.1421, Val Loss: 5.5397\n",
      "Epoch [700/1000], Run Loss: 0.3642, Val Loss: 5.8286\n",
      "Epoch [800/1000], Run Loss: 0.1430, Val Loss: 4.3438\n",
      "Epoch [900/1000], Run Loss: 0.0705, Val Loss: 4.4764\n",
      "Epoch [1000/1000], Run Loss: 0.0883, Val Loss: 5.0763\n",
      "predictions [[77.96871]], targets: [80.]\n",
      "Die Ausführungszeit beträgt: 1470.7003231048584 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_loss = train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51828aed-547a-47e5-96ca-c711b56b9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.61760416356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463260a2-5b23-4470-9c30-0fa43c7bc1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5502b-e97e-4091-91e6-c5aa363f61ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
